{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opensmile Audio Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opensmile\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path_to_directory = 'yue_audio'\n",
    "mp3_files = [os.path.join(path_to_directory, f) for f in os.listdir(path_to_directory) if f.endswith('.wav')]\n",
    "smile = opensmile.Smile(feature_set=opensmile.FeatureSet.ComParE_2016, feature_level=opensmile.FeatureLevel.Functionals)\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for mp3_file in mp3_files:\n",
    "    y = smile.process_file(mp3_file)\n",
    "    combined_df = pd.concat([combined_df, y], ignore_index=True)\n",
    "\n",
    "combined_df.to_csv('yue_audio/yue_audio_feature.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stable Diffusion Visual Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "device = 'cuda:1'\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"text2img_model/taiyi\",requires_safety_checker=False).to(device)\n",
    "\n",
    "def get_unet_output(prompt: str, timestep: int = 999) -> torch.Tensor:\n",
    "\n",
    "    text_inputs = pipe.tokenizer(\n",
    "        prompt,\n",
    "        padding=\"max_length\",\n",
    "        max_length=16,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    text_input_ids = text_inputs.input_ids.to(device)\n",
    "    text_embeddings = pipe.text_encoder(text_input_ids)[0]\n",
    "    \n",
    "    latents = torch.randn(\n",
    "        (1, pipe.unet.config.in_channels, 64, 64),  # 64x64 对应 512x512 的图像\n",
    "        device=device,\n",
    "    )\n",
    "    \n",
    "    timesteps = torch.tensor([timestep], device=device)\n",
    "    with torch.no_grad():\n",
    "        unet_output = pipe.unet(\n",
    "            latents,\n",
    "            timesteps,\n",
    "            encoder_hidden_states=text_embeddings\n",
    "        ).sample\n",
    "        \n",
    "    return unet_output\n",
    "\n",
    "\n",
    "img_feature = {}\n",
    "\n",
    "with open('ccpd_data/CCPD_text_only.txt', 'r', encoding=\"utf-8\") as f:\n",
    "    for idx, line in enumerate(f.readlines()):\n",
    "        poem = line.strip().split(',')[1]\n",
    "        print(poem)\n",
    "        img_feature[line.strip()] = get_unet_output(poem)\n",
    "\n",
    "\n",
    "with open('ccpd_unet_feture_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(img_feature, f)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
